{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base (Python 3.12.7) „Å´Êé•Á∂ö„Åï„Çå„Åæ„Åó„Åü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185dd5c8-b5bc-4d02-9c65-c37268daf61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.019799\n",
      "1 0.024436\n",
      "2 0.025237\n",
      "3 0.024219\n",
      "4 0.092040\n",
      "5 0.030415\n",
      "6 0.029540\n",
      "7 0.032878\n",
      "8 0.056548\n",
      "9 0.036003\n",
      "10 0.041020\n",
      "11 0.044827\n",
      "12 0.056489\n",
      "13 0.156947\n",
      "14 0.063221\n",
      "15 0.063829\n",
      "16 0.084704\n",
      "17 0.038641\n",
      "18 0.039937\n",
      "19 0.039667\n",
      "20 0.039256\n",
      "21 0.039217\n",
      "22 0.040374\n",
      "23 0.043571\n",
      "24 0.233508\n",
      "25 0.050457\n",
      "26 0.050018\n",
      "27 0.051100\n",
      "28 0.053062\n",
      "29 0.094523\n",
      "30 0.056005\n",
      "31 0.055768\n",
      "32 0.171605\n",
      "33 0.059072\n",
      "34 0.060494\n",
      "35 0.064563\n",
      "36 0.340242\n",
      "37 0.060926\n",
      "38 0.059661\n",
      "39 0.060663\n",
      "40 0.064234\n",
      "41 0.065268\n",
      "42 0.064141\n",
      "43 0.066438\n",
      "44 0.067845\n",
      "45 0.069574\n",
      "46 0.071869\n",
      "47 0.075418\n",
      "48 0.074839\n",
      "49 0.072386\n",
      "50 0.074063\n",
      "51 0.079094\n",
      "52 0.439696\n",
      "53 0.080934\n",
      "54 0.080015\n",
      "55 0.080789\n",
      "56 0.083614\n",
      "57 0.083984\n",
      "58 0.084729\n",
      "59 0.086988\n",
      "60 0.087131\n",
      "61 0.089595\n",
      "62 0.090406\n",
      "63 0.090462\n",
      "64 0.342293\n",
      "65 0.093676\n",
      "66 0.095898\n",
      "67 0.099206\n",
      "68 0.098732\n",
      "69 0.098941\n",
      "70 0.110716\n",
      "71 0.101827\n",
      "72 0.623265\n",
      "73 0.100419\n",
      "74 0.103887\n",
      "75 0.106794\n",
      "76 0.107179\n",
      "77 0.108768\n",
      "78 0.109363\n",
      "79 0.109392\n",
      "80 0.111885\n",
      "81 0.115047\n",
      "82 0.113814\n",
      "83 0.116863\n",
      "84 0.118866\n",
      "85 0.120590\n",
      "86 0.118820\n",
      "87 0.120580\n",
      "88 0.118593\n",
      "89 0.123115\n",
      "90 0.125604\n",
      "91 0.127339\n",
      "92 0.128982\n",
      "93 0.125762\n",
      "94 0.131049\n",
      "95 0.130869\n",
      "96 0.801670\n",
      "97 0.133601\n",
      "98 0.139320\n",
      "99 0.136205\n",
      "Performance tests passed!\n"
     ]
    }
   ],
   "source": [
    "from ctypes import resize\n",
    "import random, sys, time\n",
    "\n",
    "###########################################################################\n",
    "#                                                                         #\n",
    "# Implement a hash table from scratch! (‚ëÖ‚Ä¢·¥ó‚Ä¢‚ëÖ)                            #\n",
    "#                                                                         #\n",
    "# Please do not use Python's dictionary or Python's collections library.  #\n",
    "# The goal is to implement the data structure yourself.                   #\n",
    "#                                                                         #\n",
    "###########################################################################\n",
    "\n",
    "# Hash function.\n",
    "#\n",
    "# |key|: string\n",
    "# Return value: a hash value\n",
    "\n",
    "\n",
    "# draft\n",
    "# def char_num(char):\n",
    "#     char_to_num = {\"a\": 2, \"b\": 3, \"c\": 5, \"d\": 7, \"e\": 11, \"f\": 13, \"g\": 17, \"h\": 19, \"i\": 23, \"j\": 29, \"k\": 31, \"l\": 37, \"m\": 41, \"n\": 43, \"o\": 47, \"p\": 53, \"q\": 59, \"r\": 61, \"s\": 67, \"t\": 71, \"u\": 73, \"v\": 79, \"w\": 83, \"x\": 89, \"y\": 97, \"z\": 101,}\n",
    "    \n",
    "def calculate_hash(key):\n",
    "    assert type(key) == str\n",
    "    # Note: This is not a good hash function. Do you see why?\n",
    "    hash = 1\n",
    "    for i in key:\n",
    "        hash *= ord(i)\n",
    "    return hash\n",
    "\n",
    "\n",
    "# An item object that represents one key - value pair in the hash table.\n",
    "class Item:\n",
    "    # |key|: The key of the item. The key must be a string.\n",
    "    # |value|: The value of the item.\n",
    "    # |next|: The next item in the linked list. If this is the last item in the\n",
    "    #         linked list, |next| is None.\n",
    "    def __init__(self, key, value, next):\n",
    "        assert type(key) == str\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = next\n",
    "\n",
    "\n",
    "# The main data structure of the hash table that stores key - value pairs.\n",
    "# The key must be a string. The value can be any type.\n",
    "#\n",
    "# |self.bucket_size|: The bucket size.\n",
    "# |self.buckets|: An array of the buckets. self.buckets[hash % self.bucket_size]\n",
    "#                 stores a linked list of items whose hash value is |hash|.\n",
    "# |self.item_count|: The total number of items in the hash table.\n",
    "class HashTable:\n",
    "\n",
    "    # Initialize the hash table.\n",
    "    def __init__(self):\n",
    "        # Set the initial bucket size to 97. A prime number is chosen to reduce\n",
    "        # hash conflicts.\n",
    "        self.bucket_size = 97\n",
    "        self.buckets = [None] * self.bucket_size\n",
    "        self.item_count = 0\n",
    "        self.dic = {}\n",
    "\n",
    "    # Put an item to the hash table. If the key already exists, the\n",
    "    # corresponding value is updated to a new value.\n",
    "    #\n",
    "    # |key|: The key of the item.\n",
    "    # |value|: The value of the item.\n",
    "    # Return value: True if a new item is added. False if the key already exists\n",
    "    #               and the value is updated.\n",
    "    def put(self, key, value):\n",
    "        assert type(key) == str\n",
    "        self.check_size() # Note: Don't remove this code.\n",
    "        hash_of_key = calculate_hash(key)\n",
    "        bucket_index = hash_of_key % self.bucket_size\n",
    "        self.dic[key] = hash_of_key\n",
    "        item = self.buckets[bucket_index]\n",
    "        while item:\n",
    "            if item.key == key:\n",
    "                item.value = value\n",
    "                return False\n",
    "            item = item.next\n",
    "        new_item = Item(key, value, self.buckets[bucket_index])\n",
    "        self.buckets[bucket_index] = new_item\n",
    "        self.item_count += 1\n",
    "        self.resize()\n",
    "        return True\n",
    "\n",
    "    # Get an item from the hash table.\n",
    "    #\n",
    "    # |key|: The key.\n",
    "    # Return value: If the item is found, (the value of the item, True) is\n",
    "    #               returned. Otherwise, (None, False) is returned.\n",
    "    def get(self, key):\n",
    "        assert type(key) == str\n",
    "        self.check_size() # Note: Don't remove this code.\n",
    "        if key not in self.dic:\n",
    "            return (None,False)\n",
    "        bucket_index = self.dic[key] % self.bucket_size\n",
    "        item = self.buckets[bucket_index]\n",
    "        while item:\n",
    "            if item.key == key:\n",
    "                return (item.value, True)\n",
    "            item = item.next\n",
    "        return (None, False)\n",
    "\n",
    "    # Delete an item from the hash table.\n",
    "    #\n",
    "    # |key|: The key.\n",
    "    # Return value: True if the item is found and deleted successfully. False\n",
    "    #               otherwise.\n",
    "    def delete(self, key):\n",
    "        assert type(key) == str\n",
    "        self.check_size() # Note: Don't remove this code.\n",
    "        if key not in self.dic:\n",
    "            return False\n",
    "        bucket_index = self.dic[key] % self.bucket_size\n",
    "        item = self.buckets[bucket_index]\n",
    "        prev_item = None\n",
    "        while item:\n",
    "            if item.key == key:\n",
    "                if item == self.buckets[bucket_index]:\n",
    "                    self.buckets[bucket_index] = item.next\n",
    "                else:\n",
    "                    prev_item.next = item.next\n",
    "                self.item_count -= 1\n",
    "                self.resize()\n",
    "                return True\n",
    "            else:\n",
    "                prev_item = item\n",
    "            item = item.next\n",
    "        return False\n",
    "    \n",
    "    \n",
    "\n",
    "    # Return the total number of items in the hash table.\n",
    "    def size(self):\n",
    "        return self.item_count\n",
    "\n",
    "    # Check that the hash table has a \"reasonable\" bucket size.\n",
    "    # The bucket size is judged \"reasonable\" if it is smaller than 100 or\n",
    "    # the buckets are 30% or more used.\n",
    "    #\n",
    "    # Note: Don't change this function.\n",
    "    def check_size(self):\n",
    "        assert (self.bucket_size < 100 or\n",
    "                self.item_count >= self.bucket_size * 0.3)\n",
    "        \n",
    "    def is_resize_double(self):\n",
    "        if self.bucket_size * 0.7 < self.item_count:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_resize_half(self):\n",
    "        # Ë¶ÅÁ¥†Êï∞„Åå„ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„ÅÆ„ÄÄ30% „Çí‰∏ãÂõû„Å£„ÅüÂ†¥Âêà\n",
    "        if self.bucket_size * 0.3 > self.item_count:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Â•áÊï∞„Å´„Å™„Çã„Çà„ÅÜË™øÊï¥\n",
    "    def to_odd(self,num):\n",
    "        if num % 2 == 0:\n",
    "            num += 1\n",
    "        return num\n",
    "    \n",
    "    # „Éí„É≥„Éà 2ü§ó\n",
    "    # ÂÜç„Éè„ÉÉ„Ç∑„É•„ÇíÂÆüË£Ö„Åó„Å¶„Éá„Éº„Çø„ÇíËøΩÂä†„Åó„Å¶„ÇÇ„Åª„Åº O(1) „ÅßÂãï„Åè„Çà„ÅÜ„Å´„Åó„Çà„ÅÜ\n",
    "    # ‰Ωú„ÇäÊñπ„ÅÆ‰æãÔºö\n",
    "    # Ë¶ÅÁ¥†Êï∞„Åå„ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„ÅÆ 70% „Çí‰∏äÂõû„Å£„Åü„Çâ„ÄÅ„ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„Çí 2 ÂÄç„Å´Êã°Âºµ\n",
    "    # Ë¶ÅÁ¥†Êï∞„Åå„ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„ÅÆ 30% „Çí‰∏ãÂõû„Å£„Åü„Çâ„ÄÅ„ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„ÇíÂçäÂàÜ„Å´Á∏ÆÂ∞è\n",
    "    # „ÉÜ„Éº„Éñ„É´„Çµ„Ç§„Ç∫„ÅØÂ•áÊï∞Ôºà„Åß„Åç„Çå„Å∞Á¥†Êï∞Ôºâ„Å´„Å™„Çã„Çà„ÅÜË™øÊï¥„Åô„Çã„Å®„Éè„ÉÉ„Ç∑„É•„ÅÆË°ùÁ™Å„ÅåÊ∏õ„Çä„Åæ„Åô\n",
    "\n",
    "    def rehash(self):\n",
    "        old_hash = self.buckets\n",
    "        self.buckets = [None] * self.bucket_size\n",
    "        for item in old_hash:\n",
    "            while item:\n",
    "                next_item = item.next\n",
    "                new_index = self.dic[item.key] % self.bucket_size\n",
    "                item.next = self.buckets[new_index]\n",
    "                self.buckets[new_index] = item\n",
    "                item = next_item\n",
    "\n",
    "    \n",
    "\n",
    "    def resize(self):\n",
    "        if self.is_resize_double():\n",
    "            self.bucket_size *= 2\n",
    "            self.bucket_size = self.to_odd(self.bucket_size)\n",
    "            self.rehash()\n",
    "        elif self.is_resize_half():\n",
    "            self.bucket_size //= 2\n",
    "            self.bucket_size = self.to_odd(self.bucket_size)\n",
    "            self.rehash()\n",
    "\n",
    "\n",
    "\n",
    "# Test the functional behavior of the hash table.\n",
    "def functional_test():\n",
    "    hash_table = HashTable()\n",
    "\n",
    "    assert hash_table.put(\"aaa\", 1) == True\n",
    "    assert hash_table.get(\"aaa\") == (1, True)\n",
    "    assert hash_table.size() == 1\n",
    "\n",
    "    assert hash_table.put(\"bbb\", 2) == True\n",
    "    assert hash_table.put(\"ccc\", 3) == True\n",
    "    assert hash_table.put(\"ddd\", 4) == True\n",
    "    assert hash_table.get(\"aaa\") == (1, True)\n",
    "    assert hash_table.get(\"bbb\") == (2, True)\n",
    "    assert hash_table.get(\"ccc\") == (3, True)\n",
    "    assert hash_table.get(\"ddd\") == (4, True)\n",
    "    assert hash_table.get(\"a\") == (None, False)\n",
    "    assert hash_table.get(\"aa\") == (None, False)\n",
    "    assert hash_table.get(\"aaaa\") == (None, False)\n",
    "    assert hash_table.size() == 4\n",
    "\n",
    "    assert hash_table.put(\"aaa\", 11) == False\n",
    "    assert hash_table.get(\"aaa\") == (11, True)\n",
    "    assert hash_table.size() == 4\n",
    "\n",
    "    assert hash_table.delete(\"aaa\") == True\n",
    "    assert hash_table.get(\"aaa\") == (None, False)\n",
    "    assert hash_table.size() == 3\n",
    "\n",
    "    assert hash_table.delete(\"a\") == False\n",
    "    assert hash_table.delete(\"aa\") == False\n",
    "    assert hash_table.delete(\"aaa\") == False\n",
    "    assert hash_table.delete(\"aaaa\") == False\n",
    "\n",
    "    assert hash_table.delete(\"ddd\") == True\n",
    "    assert hash_table.delete(\"ccc\") == True\n",
    "    assert hash_table.delete(\"bbb\") == True\n",
    "    assert hash_table.get(\"aaa\") == (None, False)\n",
    "    assert hash_table.get(\"bbb\") == (None, False)\n",
    "    assert hash_table.get(\"ccc\") == (None, False)\n",
    "    assert hash_table.get(\"ddd\") == (None, False)\n",
    "    assert hash_table.size() == 0\n",
    "\n",
    "    assert hash_table.put(\"abc\", 1) == True\n",
    "    assert hash_table.put(\"acb\", 2) == True\n",
    "    assert hash_table.put(\"bac\", 3) == True\n",
    "    assert hash_table.put(\"bca\", 4) == True\n",
    "    assert hash_table.put(\"cab\", 5) == True\n",
    "    assert hash_table.put(\"cba\", 6) == True\n",
    "    assert hash_table.get(\"abc\") == (1, True)\n",
    "    assert hash_table.get(\"acb\") == (2, True)\n",
    "    assert hash_table.get(\"bac\") == (3, True)\n",
    "    assert hash_table.get(\"bca\") == (4, True)\n",
    "    assert hash_table.get(\"cab\") == (5, True)\n",
    "    assert hash_table.get(\"cba\") == (6, True)\n",
    "    assert hash_table.size() == 6\n",
    "\n",
    "    assert hash_table.delete(\"abc\") == True\n",
    "    assert hash_table.delete(\"cba\") == True\n",
    "    assert hash_table.delete(\"bac\") == True\n",
    "    assert hash_table.delete(\"bca\") == True\n",
    "    assert hash_table.delete(\"acb\") == True\n",
    "    assert hash_table.delete(\"cab\") == True\n",
    "    assert hash_table.size() == 0\n",
    "    print(\"Functional tests passed!\")\n",
    "\n",
    "\n",
    "# Test the performance of the hash table.\n",
    "#\n",
    "# Your goal is to make the hash table work with mostly O(1).\n",
    "# If the hash table works with mostly O(1), the execution time of each iteration\n",
    "# should not depend on the number of items in the hash table. To achieve the\n",
    "# goal, you will need to 1) implement rehashing (Hint: expand / shrink the hash\n",
    "# table when the number of items in the hash table hits some threshold) and\n",
    "# 2) tweak the hash function (Hint: think about ways to reduce hash conflicts).\n",
    "def performance_test():\n",
    "    hash_table = HashTable()\n",
    "\n",
    "    for iteration in range(100):\n",
    "        begin = time.time()\n",
    "        random.seed(iteration)\n",
    "        for i in range(10000):\n",
    "            rand = random.randint(0, 100000000)\n",
    "            hash_table.put(str(rand), str(rand))\n",
    "        random.seed(iteration)\n",
    "        for i in range(10000):\n",
    "            rand = random.randint(0, 100000000)\n",
    "            hash_table.get(str(rand))\n",
    "        end = time.time()\n",
    "        print(\"%d %.6f\" % (iteration, end - begin))\n",
    "\n",
    "    for iteration in range(100):\n",
    "        random.seed(iteration)\n",
    "        for i in range(10000):\n",
    "            rand = random.randint(0, 100000000)\n",
    "            hash_table.delete(str(rand))\n",
    "\n",
    "    assert hash_table.size() == 0\n",
    "    print(\"Performance tests passed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #functional_test()\n",
    "    performance_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f59fd-2c66-4656-a5e3-9b4675b4b1e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/Users/tawaraayaka/stepJapan/week2/cache.py:156\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTests passed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 156\u001b[0m     cache_test()\n",
      "File \u001b[1;32m/Users/tawaraayaka/stepJapan/week2/cache.py:82\u001b[0m\n\u001b[1;32m     79\u001b[0m cache \u001b[39m=\u001b[39m Cache(\u001b[39m4\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[39m# Initially, no page is cached.\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[39massert\u001b[39;00m cache\u001b[39m.\u001b[39mget_pages() \u001b[39m==\u001b[39m []\n\u001b[1;32m     84\u001b[0m \u001b[39m# Access \"a.com\".\u001b[39;00m\n\u001b[1;32m     85\u001b[0m cache\u001b[39m.\u001b[39maccess_page(\u001b[39m\"\u001b[39m\u001b[39ma.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAAA\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implement a data structure that stores the most recently accessed N pages.\n",
    "# See the below test cases to see how it should work.\n",
    "#\n",
    "# Note: Please do not use a library like collections.OrderedDict). The goal is\n",
    "#       to implement the data structure yourself!\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, url, contents, next):\n",
    "        self.url = url\n",
    "        self.contents = contents\n",
    "        self.next = next\n",
    "\n",
    "\n",
    "class Cache:\n",
    "    # Initialize the cache.\n",
    "    # |n|: The size of the cache.\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.cache_dic = {}\n",
    "        self.head = None\n",
    "        #------------------------#\n",
    "        # Write your code here!  #\n",
    "        #------------------------#\n",
    "        \n",
    "    def is_in_cache(self, url):\n",
    "        if url in self.cache_dic.keys():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Access a page and update the cache so that it stores the most recently\n",
    "    # accessed N pages. This needs to be done with mostly O(1).\n",
    "    # |url|: The accessed URL\n",
    "    # |contents|: The contents of the URL\n",
    "    def access_page(self, url, contents):\n",
    "        if self.is_in_cache(url):\n",
    "            # Adjust the neighboring previous nodes\n",
    "            item = self.head\n",
    "            while item.next:\n",
    "                prev_item = item\n",
    "                item = item.next\n",
    "                if item.url == url:\n",
    "                    prev_item.next = item.next\n",
    "            # Move the most recently accessed page to the head of the linked list            \n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "            \n",
    "        else:\n",
    "            #„ÄÄDelete the oldest item\n",
    "            if len(self.cache_dic) == 4:\n",
    "                item = self.head\n",
    "                while item.next:\n",
    "                    prev_item = item\n",
    "                    item = item.next\n",
    "                del self.cache_dic[item.url]\n",
    "                prev_item.next = None\n",
    "            # store this page\n",
    "            self.cache_dic[url] = contents\n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "           \n",
    "        # cache the url and contents properly\n",
    "\n",
    "\n",
    "    # Return the URLs stored in the cache. The URLs are ordered in the order\n",
    "    # in which the URLs are mostly recently accessed.\n",
    "    def get_pages(self):\n",
    "        item = self.head\n",
    "        page_lists = []\n",
    "        while item:\n",
    "            page_lists.append(item.url)\n",
    "            item = item.next\n",
    "        # return type : list[urls in order]\n",
    "\n",
    "\n",
    "def cache_test():\n",
    "    # Set the size of the cache to 4.\n",
    "    cache = Cache(4)\n",
    "\n",
    "    # Initially, no page is cached.\n",
    "    assert cache.get_pages() == []\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # \"a.com\" is cached.\n",
    "    assert cache.get_pages() == [\"a.com\"]\n",
    "\n",
    "    # Access \"b.com\".\n",
    "    cache.access_page(\"b.com\", \"BBB\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"c.com\".\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\".\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\" again.\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"a.com\" again.\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"d.com\", \"c.com\", \"b.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"d.com\", \"c.com\", \"b.com\"]\n",
    "\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    assert cache.get_pages() == [\"c.com\", \"a.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"b.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"a.com\", \"c.com\", \"d.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"a.com\", \"c.com\", \"d.com\"]\n",
    "\n",
    "    # Access \"f.com\".\n",
    "    cache.access_page(\"f.com\", \"FFF\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"c.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"f.com\", \"e.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"f.com\", \"e.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"f.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"f.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"e.com\", \"f.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"e.com\", \"f.com\", \"c.com\"]\n",
    "\n",
    "    print(\"Tests passed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cache_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aee7db-54db-48b1-ab72-b3be64f074b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/Users/tawaraayaka/stepJapan/week2/cache.py:157\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTests passed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 157\u001b[0m     cache_test()\n",
      "File \u001b[1;32m/Users/tawaraayaka/stepJapan/week2/cache.py:112\u001b[0m\n\u001b[1;32m    109\u001b[0m cache\u001b[39m.\u001b[39maccess_page(\u001b[39m\"\u001b[39m\u001b[39md.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDDD\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[39m# The cache is updated to:\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m#   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m \u001b[39massert\u001b[39;00m cache\u001b[39m.\u001b[39mget_pages() \u001b[39m==\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39md.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mc.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mb.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma.com\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    114\u001b[0m \u001b[39m# Access \"a.com\" again.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m cache\u001b[39m.\u001b[39maccess_page(\u001b[39m\"\u001b[39m\u001b[39ma.com\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAAA\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implement a data structure that stores the most recently accessed N pages.\n",
    "# See the below test cases to see how it should work.\n",
    "#\n",
    "# Note: Please do not use a library like collections.OrderedDict). The goal is\n",
    "#       to implement the data structure yourself!\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, url, contents, next):\n",
    "        self.url = url\n",
    "        self.contents = contents\n",
    "        self.next = next\n",
    "\n",
    "\n",
    "class Cache:\n",
    "    # Initialize the cache.\n",
    "    # |n|: The size of the cache.\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.cache_dic = {}\n",
    "        self.head = None\n",
    "        #------------------------#\n",
    "        # Write your code here!  #\n",
    "        #------------------------#\n",
    "        \n",
    "    def is_in_cache(self, url):\n",
    "        if url in self.cache_dic.keys():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Access a page and update the cache so that it stores the most recently\n",
    "    # accessed N pages. This needs to be done with mostly O(1).\n",
    "    # |url|: The accessed URL\n",
    "    # |contents|: The contents of the URL\n",
    "    def access_page(self, url, contents):\n",
    "        if self.is_in_cache(url):\n",
    "            # Adjust the neighboring previous nodes\n",
    "            item = self.head\n",
    "            while item.next:\n",
    "                prev_item = item\n",
    "                item = item.next\n",
    "                if item.url == url:\n",
    "                    prev_item.next = item.next\n",
    "            # Move the most recently accessed page to the head of the linked list            \n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "            \n",
    "        else:\n",
    "            #„ÄÄDelete the oldest item\n",
    "            if len(self.cache_dic) == 4:\n",
    "                item = self.head\n",
    "                while item.next:\n",
    "                    prev_item = item\n",
    "                    item = item.next\n",
    "                del self.cache_dic[item.url]\n",
    "                prev_item.next = None\n",
    "            # store this page\n",
    "            self.cache_dic[url] = contents\n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "           \n",
    "        # cache the url and contents properly\n",
    "\n",
    "\n",
    "    # Return the URLs stored in the cache. The URLs are ordered in the order\n",
    "    # in which the URLs are mostly recently accessed.\n",
    "    def get_pages(self):\n",
    "        item = self.head\n",
    "        page_lists = []\n",
    "        while item:\n",
    "            page_lists.append(item.url)\n",
    "            item = item.next\n",
    "        return page_lists\n",
    "        # return type : list[urls in order]\n",
    "\n",
    "\n",
    "def cache_test():\n",
    "    # Set the size of the cache to 4.\n",
    "    cache = Cache(4)\n",
    "\n",
    "    # Initially, no page is cached.\n",
    "    assert cache.get_pages() == []\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # \"a.com\" is cached.\n",
    "    assert cache.get_pages() == [\"a.com\"]\n",
    "\n",
    "    # Access \"b.com\".\n",
    "    cache.access_page(\"b.com\", \"BBB\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"c.com\".\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\".\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\" again.\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"a.com\" again.\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"d.com\", \"c.com\", \"b.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"d.com\", \"c.com\", \"b.com\"]\n",
    "\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    assert cache.get_pages() == [\"c.com\", \"a.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"b.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"a.com\", \"c.com\", \"d.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"a.com\", \"c.com\", \"d.com\"]\n",
    "\n",
    "    # Access \"f.com\".\n",
    "    cache.access_page(\"f.com\", \"FFF\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"c.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"f.com\", \"e.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"f.com\", \"e.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"f.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"f.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"e.com\", \"f.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"e.com\", \"f.com\", \"c.com\"]\n",
    "\n",
    "    print(\"Tests passed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cache_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28f7fc-de58-4dbf-bd94-c54be90596cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Implement a data structure that stores the most recently accessed N pages.\n",
    "# See the below test cases to see how it should work.\n",
    "#\n",
    "# Note: Please do not use a library like collections.OrderedDict). The goal is\n",
    "#       to implement the data structure yourself!\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, url, contents, next):\n",
    "        self.url = url\n",
    "        self.contents = contents\n",
    "        self.next = next\n",
    "\n",
    "\n",
    "class Cache:\n",
    "    # Initialize the cache.\n",
    "    # |n|: The size of the cache.\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.cache_dic = {}\n",
    "        self.head = None\n",
    "        #------------------------#\n",
    "        # Write your code here!  #\n",
    "        #------------------------#\n",
    "        \n",
    "    def is_in_cache(self, url):\n",
    "        if url in self.cache_dic.keys():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Access a page and update the cache so that it stores the most recently\n",
    "    # accessed N pages. This needs to be done with mostly O(1).\n",
    "    # |url|: The accessed URL\n",
    "    # |contents|: The contents of the URL\n",
    "    def access_page(self, url, contents):\n",
    "        if self.is_in_cache(url):\n",
    "            if self.head.url == url:\n",
    "                return\n",
    "            # Adjust the neighboring previous nodes\n",
    "            item = self.head\n",
    "            while item.next:\n",
    "                prev_item = item\n",
    "                item = item.next\n",
    "                if item.url == url:\n",
    "                    prev_item.next = item.next\n",
    "            # Move the most recently accessed page to the head of the linked list            \n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "            \n",
    "        else:\n",
    "            #„ÄÄDelete the oldest item\n",
    "            if len(self.cache_dic) == 4:\n",
    "                item = self.head\n",
    "                while item.next:\n",
    "                    prev_item = item\n",
    "                    item = item.next\n",
    "                del self.cache_dic[item.url]\n",
    "                prev_item.next = None\n",
    "            # store this page\n",
    "            self.cache_dic[url] = contents\n",
    "            new_item = Item(url, contents, self.head)\n",
    "            self.head = new_item\n",
    "           \n",
    "        # cache the url and contents properly\n",
    "\n",
    "\n",
    "    # Return the URLs stored in the cache. The URLs are ordered in the order\n",
    "    # in which the URLs are mostly recently accessed.\n",
    "    def get_pages(self):\n",
    "        item = self.head\n",
    "        page_lists = []\n",
    "        while item:\n",
    "            page_lists.append(item.url)\n",
    "            item = item.next\n",
    "        return page_lists\n",
    "        # return type : list[urls in order]\n",
    "\n",
    "\n",
    "def cache_test():\n",
    "    # Set the size of the cache to 4.\n",
    "    cache = Cache(4)\n",
    "\n",
    "    # Initially, no page is cached.\n",
    "    assert cache.get_pages() == []\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # \"a.com\" is cached.\n",
    "    assert cache.get_pages() == [\"a.com\"]\n",
    "\n",
    "    # Access \"b.com\".\n",
    "    cache.access_page(\"b.com\", \"BBB\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"c.com\".\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\".\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"d.com\" again.\n",
    "    cache.access_page(\"d.com\", \"DDD\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"d.com\", \"c.com\", \"b.com\", \"a.com\"]\n",
    "\n",
    "    # Access \"a.com\" again.\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"d.com\", \"c.com\", \"b.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"d.com\", \"c.com\", \"b.com\"]\n",
    "\n",
    "    cache.access_page(\"c.com\", \"CCC\")\n",
    "    assert cache.get_pages() == [\"c.com\", \"a.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    assert cache.get_pages() == [\"a.com\", \"c.com\", \"d.com\", \"b.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"b.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"a.com\", \"c.com\", \"d.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"a.com\", \"c.com\", \"d.com\"]\n",
    "\n",
    "    # Access \"f.com\".\n",
    "    cache.access_page(\"f.com\", \"FFF\")\n",
    "    # The cache is full, so we need to remove the least recently accessed page \"c.com\".\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"f.com\", \"e.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"f.com\", \"e.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"e.com\".\n",
    "    cache.access_page(\"e.com\", \"EEE\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"e.com\", \"f.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"e.com\", \"f.com\", \"a.com\", \"c.com\"]\n",
    "\n",
    "    # Access \"a.com\".\n",
    "    cache.access_page(\"a.com\", \"AAA\")\n",
    "    # The cache is updated to:\n",
    "    #   (most recently accessed)<-- \"a.com\", \"e.com\", \"f.com\", \"c.com\" -->(least recently accessed)\n",
    "    assert cache.get_pages() == [\"a.com\", \"e.com\", \"f.com\", \"c.com\"]\n",
    "\n",
    "    print(\"Tests passed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cache_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
