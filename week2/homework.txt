week2　

原文ho
https://docs.google.com/document/d/1P7-DWh6rtjNNPg_6HIfQetfBWhH9qT2tIcPyhzhaqPc/edit?tab=t.0

【homework1】
design document of hash_table.py
アルゴリズムの説明、プログラムの実行方法、工夫した点などを第三者にも伝わるように「わかりやすく」書く


概要
key(string)とvalue(何の型でもOK)をペアで持つデータを格納するためのhash tableを作った
put、get、delete機能を実装した。
ハッシュ値の割り振り
keyのhash値をcalculate_hashで計算する。それぞれのkeyに何らかの値を与えた。    
格納
hash値をbucket_sizeで割り算してhash tableに格納した。ハッシュ値が衝突した際には、連結リストで繋いだ。
再ハッシュ
要素数がbucket sizeの70%以上（つまりキャパが埋まってきた時）はハッシュテーブルの長さを二倍にした。逆に、要素数がbucket sizeの30%以下（つまりすかすかな時）はハッシュテーブルの長さを半分にした。この時、bucket sizeは必ず奇数になるようにした。

実行方法
functional_test
いくつかの具体的なkeyとvalueを入力し、put、get、deleteを試した

performance_test
0~1億のうちから乱数を生成し、それらをkeyとvalueにして100回ずつput、get、deleteした。







工夫した点
ハッシュ関数を工夫した。元々 Σord(char) だったが、Πord(char)にした

課題、不明点
ハッシュ関数がまだ改善できそう
そもそも積にした方が良いのか？？どうせbucket_sizeで割ってしまうから衝突するかどうかは和でも積でも変わらないのでは？
ハッシュ値をユニークなものにするという視点だけで考えると、例えば、ord(char)ではなく、char一つ一つに新たに素数を割り当てて、それらの積を取った方が良い？
そうなると、a~z、A~Z、0~9、その他記号にも割り当てる必要がある？？
bucket sizeを奇数にしたが、近くのprime numberを探して設定しても良いかもしれない（find_prime_number()みたいな関数を作る？でも素数の探索って意外と大変かもしれない）

【homework2】
木構造を使えば O(log N)、ハッシュテーブルを使えばほぼ O(1) で検索・追加・削除を実現することができて、これだけ見ればハッシュテーブルのほうが優れているように見える。ところが現実の大規模なデータベースでは、ハッシュテーブルではなく木構造が使われることが多い。その理由を考えよ。
いくつか重要な理由があるので思いつくだけ書いてください！

木構造の場合、大きさを指定しなくて良いから。ハッシュテーブルは大きさを指定する必要がある。例えば、googleのユーザのDBを作ろうとしたら、総ユーザ数を予想するのは難しいし、ユーザの増加によって再ハッシュするのは、Nが大きくなればなるほど大変だから。
構造を変えるのが簡単（例えば、授業で扱ったbalance木も数箇所いじるだけで全体の構造を調整することができた）で、扱いやすいから。

【homework3】
もっとも単純には、「URL」をキー、「Webページ」を値とするハッシュテーブルを用意すればよい
もっとも直近にアクセスされたページ上位 X 個をキャッシュしておく😊
アクセス系列が「A, A, A, A, B, A, C, D, D, B, B, D, B, E」ならば、「B, D, E」をキャッシュ
このようなキャッシュの管理をほぼ O(1) で実現できるデータ構造を考えてください！(σ⁎˃ᴗ˂⁎)σ

hashtableとlinked nodeを組み合わせる
hashtableでキャッシュリストに存在するかどうかを確認
linked listで順番を作る -> deleteしやすい、順番変えやすい

【homework4】
design document of cache.py
アルゴリズムの説明、プログラムの実行方法、工夫した点などを第三者にも伝わるように「わかりやすく」書く

アルゴリズムの説明
ブラウザのキャッシュ機能（最近アクセスされたN個のwebsiteのキャッシュ）の実装
キャッシュは新たに追加された順に並べておく、ただし計算量はO(1)
何らかのページにアクセスする。キャッシュを確認する。
もしキャッシュにそのページがなければ、キャッシュに追加する。N個しか保存できないため、一番古いページは捨てる。
もしキャッシュにあれば、キャッシュのメンツ自体は変えない。一方で、新しい順に管理したいので、最新アクセスとしてステータスを更新する。
この「新しい順」というのは連結リストで管理している。
プログラムの実行方法
tests caseで確認
最初の1~N個目
N個cacheに保存された後に
cacheに存在しないページへのアクセス
存在するページへのアクセス
latestページにさらにアクセス
latestではないページへのアクセス
oldestページへのアクセス

工夫した点
hashtableとlinked listの併用による効率的なcache
連結リストの一つ前の要素を参照するとき、連結リストをひとつひとつ追うと、たとえば一番古い要素を消したい時に、一番古い要素の一個前まで追う必要がある
-> キャッシュのキャパをNとすると計算量O(N)かかる
->これを解消するために.prevを導入し、計算量を減らした
prevをいちいち設定する手間が増えるので、Nが小さい時はnextだけの導入の方が早い？
ほぼ同じくらいだった
Nが大きい時はprev導入後の方が早い
実際そうだった

cache size = 4(頂いたテストケース)の時
.nextのみ
Execution time : 0.0002941250022558961
.nextと.prev
Execution time : 0.00016120799773489125



cache size = 10000, Number of accesses: 100000の時
.nextのみ
Accessed 0 pages
Executed time : 0.00019545800023479387
Accessed 20000 pages
Executed time : 2.017112375000579
Accessed 40000 pages
Executed time : 4.435939125000004
Accessed 60000 pages
Executed time : 4.538836667001306
Accessed 80000 pages
Executed time : 4.541467457998806
Large cache test completed!
Cache size: 10000
Number of accesses: 100000
ExecuTion time: 20.1014 seconds
Number of pages stored in cache: 10000
Most recent pages (top 10): ['page12282.com', 'page06835.com', 'page09564.com', 'page08255.com', 'page10761.com', 'page14284.com', 'page16413.com', 'page00554.com', 'page02852.com', 'page00808.com']	

.nextと.prev
Accessed 0 pages
Executed time : 0.0002280000007885974
Accessed 20000 pages
Executed time : 0.8621454999993148
Accessed 40000 pages
Executed time : 1.3470417919998
Accessed 60000 pages
Executed time : 1.393967750002048
Accessed 80000 pages
Executed time : 1.422113332999288
Large cache test completed!
Cache size: 10000
Number of accesses: 100000
Execution time: 6.4658 seconds
Number of pages stored in cache: 10000
Most recent pages (top 10): ['page00182.com', 'page18616.com', 'page12342.com', 'page15184.com', 'page11535.com', 'page04046.com', 'page00581.com', 'page04906.com', 'page09249.com', 'page09152.com']

